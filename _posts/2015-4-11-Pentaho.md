---
layout: post
title: Pentaho Overview
comments: true
tags:
- Pentaho
- Code
---

## Pentaho Business Analytics
Allows you to visualise and analyse data stored in any format - even from any step in a pentaho transformation.

There is a **semantic layer** that can be created from either *Metadata* or a *Mondrain cube schema* on top of which there are multiple reporting posibilities:

1. **Interactive reports** - Allow you to create reports using a drag and drop template based web interface - these reports can have interactive elements that can allow the users to filter the data contained in the final report.
![Interactive Reports](http://infocenter.pentaho.com/help/topic/getting_started_with_pentaho/images/ssGettingStartedInteractiveScreen1.png)

2. **Analyzer** - Allows you to represent data and patterns visually to aid in making business decisions - this includes charts, graphs, heat grids and geographic visualisations.
![Analyzer](http://infocenter.pentaho.com/help/topic/getting_started_with_pentaho/images/ssgetstartedwidgetAnalyzerPanel.png)

3. **Dashboard designer** - Allows you to add report elements from both interactive reports, analyzer and multiple other sources in to one dashboard to show data represented in different formats.
![Dashboard Designer](http://infocenter.pentaho.com/help/topic/getting_started_with_pentaho/images/ssgetstartedwidgetDashboardPanel.png)

4. **Report Designer** - Report creation tool that allows highly detailed reports to be generated from virtually any data source.
![Report Designer](http://reportipedia.com/reportingsoftware/SoftwareImages/pentaho_report_designer.jpg)

_____________________________________________________________________________________________________________________________

## Pentaho Data Itegration
The data integration element is split into three components comprised of the DI server, Spoon Design Tool and Command line utils and Plugins.

The **Data Integration Server** runs the transformations and jobs that are created in **Spoon**. The server also contains a DI repo and a processing engine, a service layer for security and a scheduling tool.

**Spoon** is a GUI tool that allows DI transformations and jobs to be created through a drag and drop interface - it can execute these jobs then on the DI server and provide the outputs/results for each step in the transformation/process.

### Transformations
Transformations contain all the components for an individual transformation usually comprising of an input and output step.
![Transformation](http://www.sentric.ch/wp-content/uploads/2013/01/Pentaho-Data-Integration-Graphical-Designer.png)

### Jobs
A job sits a level above transformations and allows several transformations to be strung together and provides other high level steps.
![Job](https://splicemachine.zendesk.com/hc/en-us/article_attachments/200777378/pentaho_ky6r_job.png)

_____________________________________________________________________________________________________________________________

## Pentaho with Big Data

PDI can be used to write *MapReduce* applications and initiate them from multiple technologies including **Java**, **Hadoop streaming**, **Hive**, **Pig** and others - this allows MapReduce jobs to be run natively on the Hadoop cluster so the power of the cluster is still utilised.
Data can also be extracted from HDFS into a large variety of other sources and also allows the use for Sqoop.

Using PDI with Big Data services such as HDFS should be done cautiously to ensure data isn't read and written, to and from the Hadoop cluster to be processed by the PDI engine/server if they are stored remotely, as this will not utilise the full resources available on the cluster. To combat this, the PDI tool has built in functionality to create MapReduce jobs as well as to set up and deploy a yarn application that can be pushed down to a cluster and run PDI transformations and jobs in a distributed way across the cluster without MapReduce as the driver.
